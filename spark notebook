spark notebook
http://www.jerrynest.com/ubuntu-spark-notebook/
有hadoop在9000
https://github.com/andypetrella/spark-notebook/blob/master/details.md

export HADOOP_CONF_DIR=/etc/hadoop/conf
export SPARK_HOME=/usr/lib/spark
export SPARK_WORKER_DIR=/var/run/spark/work
export EXTRA_CLASSPATH=/usr/lib/hadoop-lzo/lib/hadoop-lzo.jar:/etc/hive/conf
./bin/spark-notebook -Dconfig.file=./conf/application.conf -Dhttp.port=8989


http://hadoopspark.blogspot.tw/2015/09/4-hadoop-26-single-node-cluster.html#more




##下錯了 變成1.6.1...
tar zxf spark-1.6.0-bin-hadoop2.6.tgz
sudo mv spark-1.4.0-bin-hadoop2.6 /usr/local/spark
sudo vim ~/.bashrc
#export SPARK_HOME=/usr/local/spark
#export PATH=$PATH:$SPARK_HOME/bin
source ~/.bashrc
spark-shell

cd /usr/local/spark/conf
cp log4j.properties.template log4j.properties
sudo vim log4j.properties
#第一個INFO改為WARN

spark-shell

dfs路徑要注意
以目前為例
以/usr/mao為home